{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emiel Steegh   - s1846388  \n",
    "Freek Nijweide - s1857746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "# TODO mention dat we plotly doen niet matplotlib\n",
    "# TODO write description\n",
    "# TODO FREEK GRaph Titel\n",
    "# Math Proof van 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "# TODO emiel: kopieer je shit hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "# TODO freek: maak dit af\n",
    "# TODO freek: kopieer je shit hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The following includes are needed to work with graphs and display solutions.\n",
    "from __future__ import division\n",
    "import networkx as nx\n",
    "from IPython.core.display import display\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from graphs import *\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "print(\"imports done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Code Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#General code definitions\n",
    "def generate_M_and_v(graph):\n",
    "    #type: (nx.DiGraph) -> any\n",
    "    M = nx.to_numpy_matrix(graph) #type: np.matrix\n",
    "    M.transpose()\n",
    "    M_T = M.transpose()\n",
    "    v = list(graph.nodes)\n",
    "    return M,v\n",
    "\n",
    "def pagerank(graph,beta): #Made for assignment 4, but needed in assignment 3\n",
    "    #type: (nx.DiGraph, float) -> any\n",
    "    M,nodes = generate_M_and_v(graph)\n",
    "    for i in range(len(nodes)):\n",
    "        node=nodes[i]\n",
    "        if graph.out_degree(node) > 0:\n",
    "            M[i] /= graph.out_degree(node)\n",
    "    M=M.T # We were working with adjacency matrix. The transition matrix is a transpose of this, where each\n",
    "    #       number is divided by the out-degree of the node the edge is coming from\n",
    "    original_v=np.ones(len(M),dtype=float)/len(M)\n",
    "    v = np.copy(original_v)\n",
    "    change_was_made = True\n",
    "    while change_was_made:\n",
    "        previous_v = np.copy(v)\n",
    "        first_term = beta* (np.array(np.dot(M,v)).flatten())\n",
    "        second_term = np.dot((1-beta),original_v)\n",
    "        v = first_term + second_term\n",
    "        change_was_made = ((abs(v-previous_v).max() ) > 0.00000000000001) #This 0.00... number was experimentally chosen. Smaller values seemed not to converge, for some graphs \n",
    "    \n",
    "    return v\n",
    "\n",
    "def wrap_pagerank_in_dict(graph,beta=0.85): #Made for assignment 4, but needed in assignment 3\n",
    "    values = pagerank(graph,beta)\n",
    "    keys = list(graph.nodes())\n",
    "    return dict(zip(keys,values))\n",
    "\n",
    "def order_nodes_by_rank(nodes, rank):    \n",
    "    order = np.argsort(rank)[::-1] #sort in degrees in descending order, return indices\n",
    "    sorted_nodes = [nodes[i] for i in order] #Human readable sorted list of nodes\n",
    "    ordinal_rank = [list(order).index(i) for i in range(len(order))] # Ordinal rank as specified in exercise\n",
    "    return sorted_nodes,ordinal_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_network(n_count, out_d_count, in_d_count):\n",
    "    '''\n",
    "    Generates a network around T (Target) with\n",
    "    n inaccesible pages for T\n",
    "    P accessible pages with a link to T\n",
    "    f supporting pages (link back and forth to T)   \n",
    "    '''\n",
    "    \n",
    "    G = nx.DiGraph()   \n",
    "   \n",
    "    for n in range(0, n_count):\n",
    "        new_node = \"n[{}]\".format(n)\n",
    "        G.add_node(new_node)\n",
    "        \n",
    "        nodes_in_network = list(G.nodes())\n",
    "        nodes_in_network.remove(new_node)\n",
    "        \n",
    "        current_node_count = len(nodes_in_network)\n",
    "        \n",
    "        if current_node_count < out_d_count:\n",
    "            nodes_out_index = random.sample(range(current_node_count), current_node_count)\n",
    "        else:\n",
    "            nodes_out_index = random.sample(range(current_node_count), out_d_count)\n",
    "        \n",
    "        if current_node_count < in_d_count:\n",
    "            nodes_in_index = random.sample(range(current_node_count), current_node_count)\n",
    "        else:\n",
    "            nodes_in_index = random.sample(range(current_node_count), in_d_count)\n",
    "        \n",
    "        for index in nodes_out_index:\n",
    "            G.add_edge(new_node, nodes_in_network[index])\n",
    "            \n",
    "        for index in nodes_in_index:\n",
    "            G.add_edge(nodes_in_network[index], new_node)\n",
    "        \n",
    "    return G\n",
    "\n",
    "# Generate a graph we will use in the next exercise\n",
    "def generate_test_web():\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    graph.add_edge('Google', 'Bing')\n",
    "    graph.add_edge('Google', 'Reddit')\n",
    "    graph.add_edge('Reddit', 'Trap')\n",
    "    graph.add_edge('Spider','Trap')\n",
    "    graph.add_edge('Trap','Spider')\n",
    "    graph.add_edge('Reddit', 'Apple')\n",
    "    graph.add_edge('Reddit', 'Wikipedia')\n",
    "    graph.add_edge('Apple', 'Twitter')\n",
    "    graph.add_edge('Twitter', 'Bing')\n",
    "    graph.add_edge('Wikipedia', 'Twitter')\n",
    "    graph.add_edge('Bing', 'Wikipedia')\n",
    "    graph.add_edge('Apple', 'Wikipedia')\n",
    "    graph.add_edge('Bing','Google')\n",
    "    graph.add_edge('Bing','Dead end')\n",
    "    graph.add_edge('IN node','Apple')\n",
    "    graph.name = \"Big web graph (for testing)\"\n",
    "\n",
    "    return graph\n",
    "\n",
    "def gen_arrow():\n",
    "    G = fromDot('''\n",
    "    strict digraph A {\n",
    "    A -> B -> C -> D -> E;\n",
    "    }''')\n",
    "    G.name = \"Arrow graph\"\n",
    "    return nx.DiGraph(G)\n",
    "    \n",
    "def gen_inward():\n",
    "    G = fromDot('''\n",
    "    strict digraph A {\n",
    "    {B C D E F G } -> A;\n",
    "    }''')\n",
    "    G.name = \"Inward graph\"\n",
    "    return nx.DiGraph(G)\n",
    "\n",
    "def gen_lasso():\n",
    "    G = fromDot('''\n",
    "    strict digraph A {\n",
    "    A -> B -> C -> D -> E -> A;\n",
    "    A -> E -> D -> C -> B -> A;\n",
    "    A -> F -> G;\n",
    "    }''')\n",
    "    G.name = \"Lasso graph\"\n",
    "    return nx.DiGraph(G)\n",
    "\n",
    "def gen_grid():\n",
    "    G = fromDot('''\n",
    "    strict digraph A {\n",
    "    A -> {B D};\n",
    "    B -> {C E};\n",
    "    \n",
    "    C -> {F};\n",
    "    D -> {E G};\n",
    "    E -> {F H};\n",
    "    F -> {I};\n",
    "    G -> {H};\n",
    "    H -> {I};\n",
    "    I -> {};\n",
    "    }''')\n",
    "    G.name = \"Grid graph\"\n",
    "    return nx.DiGraph(G)\n",
    "\n",
    "\n",
    "graphs = [\n",
    "generate_test_web(),\n",
    "gen_arrow(),\n",
    "gen_inward(),\n",
    "gen_lasso(),\n",
    "gen_grid()\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    print graph.name\n",
    "    display(draw(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def return_T_rank(G_o, P_count, quality, f_count, ordered_nodes):\n",
    "    \n",
    "    G = G_o.copy()\n",
    "    \n",
    "    nodes_count = len(G.nodes())\n",
    "\n",
    "    P_T_connections = []\n",
    "    \n",
    "    index = int(round(quality*nodes_count))\n",
    "    for P in range(P_count):\n",
    "        P_T_connections.append(ordered_nodes[index-P-1])\n",
    "    \n",
    "    attrs = {}\n",
    "    attrs['T'] = {'style' : 'filled', 'fillcolor' : 'red'}\n",
    "    \n",
    "    G.add_node('T')\n",
    "    \n",
    "    #connect T to all P\n",
    "    for P in P_T_connections:\n",
    "        G.add_edge(P, 'T')\n",
    "        attrs[P] = {'style' : 'filled', 'fillcolor' : 'yellow'}\n",
    "    \n",
    "    #connect T and it's supporting pages\n",
    "    for f in range(int(f_count)):\n",
    "        new_f = \"f[{}]\".format(f)\n",
    "        G.add_edge('T', new_f)\n",
    "        G.add_edge(new_f, 'T')\n",
    "        attrs[new_f] = {'style' : 'filled', 'fillcolor' : '#f5f5dc'}\n",
    "    \n",
    "    drawing = False\n",
    "    if drawing:\n",
    "        nx.set_node_attributes(G, attrs)\n",
    "        display(draw(G))\n",
    "    \n",
    "    pr = pagerank(G, 0.85)\n",
    "    T_pagerank = pr[list(G.nodes).index('T')]\n",
    "    pagerank_order, ordinal = order_nodes_by_rank(list(G.nodes),pr)\n",
    "    T_pagerank_index = pagerank_order.index('T')\n",
    "    reported_percentage = 100 - (T_pagerank_index / len(pr) * 100)\n",
    "    adjusted_percentage = 100 - (T_pagerank_index / (len(pr)-f_count) * 100)\n",
    "    \n",
    "    return T_pagerank, reported_percentage, adjusted_percentage\n",
    "\n",
    "def plot_results(ls_data_in, title_in, q_range,):\n",
    "\n",
    "    l_title = '{} of T based on f and r'.format(title_in)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    itter = 0\n",
    "    for data in ls_data_in:\n",
    "        fig.add_trace(go.Surface(\n",
    "                        visible=False,\n",
    "                        name=\"P = {}\".format(itter),\n",
    "                        z=data, y=100*(1-q_range)))\n",
    "        itter += 1\n",
    "        \n",
    "#     fig.add_trace(contours_z=dict(show=True,\n",
    "#                                         usecolormap=True,\n",
    "#                                         highlightcolor=\"limegreen\",\n",
    "#                                         project_z=True))\n",
    "\n",
    "    fig.update_layout(title=l_title,\n",
    "                    autosize=True,\n",
    "                    scene = dict(\n",
    "                    xaxis_title='ammount of supporting pages',\n",
    "                    yaxis_title='percentile of pagerank gained from accessible pages',\n",
    "                    zaxis_title=title_in))\n",
    "    \n",
    "    fig.data[0].visible = True\n",
    "    \n",
    "    #code for sliders from slider example: https://plot.ly/python/sliders/\n",
    "    steps = []\n",
    "    for i in range(len(fig.data)):\n",
    "        step = dict(\n",
    "            method=\"restyle\",\n",
    "            args=[\"visible\", [False] * len(fig.data)],\n",
    "        )\n",
    "        step[\"args\"][1][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=10,\n",
    "        currentvalue={\"prefix\": \"Frequency: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def wrapper(Graph, P_range, q_range, f_range):\n",
    "    nodes_count = len(G.nodes())\n",
    "    max_P_count = int(nodes_count/len(q_range))\n",
    "    P_count = max(P_range)\n",
    "    \n",
    "    if P_count > max_P_count:\n",
    "        print \"The number of accessible pages (P) cannot be larger than {} for the current quality range (q)\".format(max_P_count)\n",
    "        return None\n",
    "    \n",
    "    ranked_nodes = pagerank(G, .85)\n",
    "    ordered_nodes, ordinal_rank = order_nodes_by_rank(list(G.nodes),ranked_nodes)\n",
    "\n",
    "    ls_results_pagerank = []\n",
    "    ls_results_percentile = []\n",
    "    ls_results_percentile_adj = []\n",
    "    \n",
    "    for index_P in range(len(P_range)):\n",
    "        print \"working on P = {}\".format(index_P)\n",
    "        \n",
    "        results_pagerank = np.zeros([len(q_range),len(f_range)])\n",
    "        results_percentile = np.zeros([len(q_range),len(f_range)])\n",
    "        results_percentile_adj = np.zeros([len(q_range),len(f_range)])\n",
    "\n",
    "        for index_f in range(len(f_range)):\n",
    "            for index_q in range(len(q_range)):\n",
    "                f_count = f_range[index_f]\n",
    "                quality = q_range[index_q]\n",
    "                T_pagerank, T_percentile, T_percentile_adj = return_T_rank(G, index_P, quality, f_count, ordered_nodes)\n",
    "                results_pagerank[index_q][index_f] = T_pagerank\n",
    "                results_percentile[index_q][index_f] = T_percentile\n",
    "                results_percentile_adj[index_q][index_f] = T_percentile_adj\n",
    "        \n",
    "        ls_results_pagerank.append(results_pagerank)\n",
    "        ls_results_percentile.append(results_percentile)\n",
    "        ls_results_percentile_adj.append(results_percentile_adj)\n",
    "    \n",
    "    plot_results(ls_results_pagerank, \"Pagerank\", q_range)\n",
    "    plot_results(ls_results_percentile, \"Pagerank percentile \",q_range)\n",
    "    plot_results(ls_results_percentile_adj, \"Adjusted pagerank percentile\",q_range)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "            \n",
    "G = generate_network(200, 3, 0)\n",
    "P_range = np.linspace(0,6,7)\n",
    "q_range = np.linspace(0.1,1,10)\n",
    "f_range = np.linspace(0,10,11)\n",
    "#f_range = np.linspace(0,3,4)\n",
    "wrapper(G, P_range, q_range, f_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create a spamfarm graph\n",
    "#PageRank + Spider-trap avoidane and beta .85\n",
    "\n",
    "\n",
    "def calc_pagerank_contrib(group, pageranks, beta):\n",
    "    r = 0\n",
    "    for node in group:\n",
    "        r += beta * pageranks[node]\n",
    "    \n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def change_supports(n_count, P_count, f_minmax):\n",
    "    d = {}\n",
    "    d['x'] = [] # supports of T\n",
    "    d['y'] = [] # pagerank of T\n",
    "    \n",
    "    f_min = min(f_minmax)\n",
    "    f_max = max(f_minmax)\n",
    "    for supports in range(f_min, f_max+1):\n",
    "        G, nodes_dict = generate_network(n_count,P_count,supports)\n",
    "        pr = wrap_pagerank_in_dict(G)\n",
    "        \n",
    "        d['x'].append(supports)\n",
    "        d['y'].append(pr[\"T\"])\n",
    "        \n",
    "    tlabel = ('PageRank of Target page T vs. Amount of support pages for T ')\n",
    "    xlabel = ('Amount of support pages linked to T (unitless)')\n",
    "    ylabel = ('PageRank of T (unitless)')\n",
    "\n",
    "    plot = go.Figure(data=go.Scatter(d, mode='lines+markers'))\n",
    "    plot.update_layout(title = tlabel,\n",
    "                      xaxis_title = xlabel,\n",
    "                      yaxis_title = ylabel)\n",
    "    plot.show()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def change_accessibles(n_count, P_minmax, f_count):\n",
    "    d = {}\n",
    "    d['x'] = [] # prominent pages T get links from\n",
    "    d['y'] = [] # pagerank of T\n",
    "    d_r = {}\n",
    "    d_r['x'] = [] # prominent pages T get links from\n",
    "    d_r['y'] = [] # r of T produced by the P pages\n",
    "    d_ra = {}\n",
    "    d_ra['x'] = [] # prominent pages T get links from\n",
    "    d_ra['y'] = [] # r of T produced by the P page\n",
    "    \n",
    "    P_min = min(P_minmax)\n",
    "    P_max = max(P_minmax)\n",
    "    for pages in range(P_min, P_max+1):\n",
    "        G, nodes_dict = generate_network(n_count,pages,f_count)\n",
    "        pr = wrap_pagerank_in_dict(G)\n",
    "        \n",
    "        d['x'].append(pages)\n",
    "        d['y'].append(pr[\"T\"])\n",
    "        d_r['x'].append(pages)\n",
    "        d_r['y'].append(calc_pagerank_contrib(nodes_dict[\"P\"], pr, 0.85))\n",
    "        \n",
    "        d_ra['x'].append(pages)\n",
    "        pr_avg = 0\n",
    "        for p, r in pr.items():\n",
    "            pr_avg += r\n",
    "        pr_avg /= len(pr)\n",
    "        d_ra['y'].append(pr_avg)\n",
    "        \n",
    "    \n",
    "    \n",
    "    tlabel = ('PageRank of Target page T vs. Amount of accesible pages for T ')\n",
    "    xlabel = ('Accissible pages linking to T (unitless)')\n",
    "    ylabel = ('PageRank (unitless)')\n",
    "\n",
    "    plot = go.Figure()\n",
    "    plot.add_trace(go.Scatter(\n",
    "                            d, \n",
    "                            mode='lines+markers',\n",
    "                            line=dict(color = \"red\"),\n",
    "                            name = 'PageRank of T'))\n",
    "    plot.add_trace(go.Scatter(\n",
    "                            d_r,\n",
    "                            mode='lines+markers',\n",
    "                            line=dict(color = \"pink\"),\n",
    "                            name = 'PageRank contribution of P to T'))\n",
    "    plot.add_trace(go.Scatter(\n",
    "                            d_ra,\n",
    "                            mode='lines+markers',\n",
    "                            line=dict(color = \"grey\"),\n",
    "                            name = 'average pagerank'))\n",
    "    plot.update_layout(title = \n",
    "                            tlabel,\n",
    "                            xaxis_title = xlabel,\n",
    "                            yaxis_title = ylabel)\n",
    "    plot.update_layout(\n",
    "        legend = go.layout.Legend(\n",
    "        x=0,y=1))\n",
    "    \n",
    "    plot.show()\n",
    "    \n",
    "    return None\n",
    "        \n",
    "\n",
    "# pr = nx.pagerank(G)\n",
    "# pp.pprint(pr)\n",
    "# calc_pagerank_contrib(nodes_dict[\"P\"], pr, 0.85)\n",
    "\n",
    "G = generate_network(50,10,5)[0]\n",
    "display(draw(G)) # default network\n",
    "change_supports   (50,10    ,[0,30])\n",
    "change_accessibles(50,[0,30],5)\n",
    "pp.pprint(wrap_pagerank_in_dict(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "\n",
    "There are three different ranking systems discussed in this week's chapters and lectures.\n",
    "The first is an inDegree-based ranking system. The ranking of a page depends on how many pages link to it.\n",
    "This system is easily fooled, and dead-end pages receive incredibly high rankings.\n",
    "\n",
    "The second ranking system discussed is Google's PageRank. This system expands upon the idea of inDegree rankings,\n",
    "by having a node \"spread\" its incoming ranking over its outgoing links. This can also include a degree of randomness,\n",
    "where a node will spread some of its incoming ranking over *all* nods (to avoid spider traps and dead ends).\n",
    "\n",
    "The third ranking system discussed HITS, based on the hub-authority model. In this model, a page is considered a good hub\n",
    "if it links to good authorities (pages with good content that people want to see). A page is considered a good\n",
    "authority if it is linked to by proper hubs. The page's authority ranking is the one actually used in the search.\n",
    "\n",
    "\n",
    "# TODO write equations\n",
    "# TODO leg code uit ( comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Note: the pagerank functions can be found at the top of the file, as they were needed in assignment 3 already\n",
    "def generate_indegree_score(graph):    \n",
    "    in_degrees = []\n",
    "    for node in graph.nodes:\n",
    "        if type(graph) == nx.classes.digraph.DiGraph:\n",
    "            in_degrees.append(graph.in_degree(node))\n",
    "        else:\n",
    "            in_degrees.append(graph.degree(node))\n",
    "    return in_degrees\n",
    "    \n",
    "\n",
    "\n",
    "def ordinal_difference(a, b):\n",
    "    if type(a) == list:\n",
    "        a = np.array(a,dtype=float)\n",
    "    if type(b) == list:\n",
    "        b = np.array(b,dtype=float)\n",
    "    return sum(abs(a-b))\n",
    "\n",
    "def hits(M):\n",
    "    if type(M) != np.matrix:\n",
    "        M = nx.adjacency_matrix(M)\n",
    "    v=np.ones(len(M),dtype=float)\n",
    "    change_was_made = True\n",
    "    h=np.copy(v)\n",
    "    a=np.copy(v)\n",
    "    while change_was_made:\n",
    "        #calculate new v for hub and authority\n",
    "        # M remains unchanged\n",
    "        previous_a = np.copy(a)\n",
    "        previous_h = np.copy(h)\n",
    "        \n",
    "        a = np.array(np.dot(M.transpose(),h)).flatten()\n",
    "        a /= a.max()\n",
    "\n",
    "        h = np.array(np.dot(M,a)).flatten()\n",
    "        h /= h.max()\n",
    "        change_was_made = ((abs(a-previous_a).max() ) > 0) or ((abs(h-previous_h).max() ) > 0) \n",
    "    \n",
    "    return a,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prints = False #turn this to true to enable printing of more info!\n",
    "\n",
    "graph = generate_test_web()\n",
    "graphs = [generate_test_web(), gen_lasso(), gen_arrow(),gen_inward(),gen_grid()]\n",
    "differences=[]\n",
    "for graph in graphs:\n",
    "    M,v = generate_M_and_v(graph)\n",
    "    if prints:\n",
    "        print graph.name\n",
    "        print str(v) + \"\\n\"\n",
    "    \n",
    "    in_degrees = generate_indegree_score(graph)\n",
    "    human_readable, indegree_order = order_nodes_by_rank(v, in_degrees)\n",
    "    if prints:\n",
    "        print \"Solution to in_degree ranking:\"\n",
    "        print \"Human readable ranking (nodes sorted by their rank): \" + str(human_readable)\n",
    "        print \"Ordinal ranking: \" + str(indegree_order) + \"\\n\"\n",
    "\n",
    "    a , h = hits(M)\n",
    "    human_readable, hits_order = order_nodes_by_rank(v, a)\n",
    "    if prints:\n",
    "        print \"Our solution to HITS ranking\"\n",
    "        print \"Human readable ranking: \" + str(human_readable)\n",
    "        print \"Ordinal ranking: \" + str(hits_order) + \"\\n\"\n",
    "\n",
    "        print \"HITS ranking (networkx implementation, for reference)\"\n",
    "    (real_h_dict, real_a_dict) = nx.hits(graph,max_iter=100000)\n",
    "    \n",
    "    difference = []\n",
    "    real_a=[]\n",
    "    for i in range(len(v)):\n",
    "        node = v[i]\n",
    "        real_a.append(real_a_dict[node])\n",
    "        difference.append(abs(real_a_dict[node]-a[i]))\n",
    "        \n",
    "    real_human_readable, real_hits_order = order_nodes_by_rank(v, real_a)\n",
    "    if prints:\n",
    "        print \"Human readable ranking: \" + str(real_human_readable)\n",
    "        print \"Ordinal ranking: \" + str(real_hits_order)\n",
    "        print \"Ordinal ranking difference between our implementation and networkx: \" + str (ordinal_difference(hits_order,real_hits_order)) + \"\\n\"\n",
    "\n",
    "\n",
    "    \n",
    "    page_rank_list = pagerank(graph,0.85)\n",
    "    human_readable, pagerank_order = order_nodes_by_rank(v, page_rank_list)\n",
    "    if prints:\n",
    "        print \"Our solution to pagerank\"\n",
    "        print \"Human readable ranking: \" + str(human_readable)\n",
    "        print \"Ordinal ranking: \" + str(pagerank_order) + \"\\n\"\n",
    "        print \"pagerank (networkx implementation, for reference)\"\n",
    "    (real_v_dict) = nx.pagerank(graph,max_iter=100000)\n",
    "    \n",
    "    difference = []\n",
    "    real_v=[]\n",
    "    for i in range(len(v)):\n",
    "        node = v[i]\n",
    "        real_v.append(real_v_dict[node])\n",
    "        difference.append(abs(real_v_dict[node]-real_v[i]))\n",
    "        \n",
    "    real_human_readable, real_pagerank_order = order_nodes_by_rank(v, real_v)\n",
    "    if prints:\n",
    "        print \"Human readable ranking: \" + str(real_human_readable)\n",
    "        print \"Ordinal ranking: \" + str(real_pagerank_order)\n",
    "        print \"Ordinal ranking difference between our implementation and networkx: \" + str (ordinal_difference(pagerank_order,real_pagerank_order))\n",
    "\n",
    "    differences.append([ordinal_difference(indegree_order,hits_order),\n",
    "                        ordinal_difference(indegree_order,pagerank_order),\n",
    "                        ordinal_difference(hits_order,pagerank_order),\n",
    "                        ordinal_difference(hits_order,real_hits_order),\n",
    "                        ordinal_difference(pagerank_order,real_pagerank_order),\n",
    "                        ])\n",
    "    if prints:\n",
    "        print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "graphs=[\"Big (n=10) web\", \"Lasso\", \"Arrow\", \"Inward\", \"Grid\"]\n",
    "indegree_hits_diff = [x[0] for x in differences]\n",
    "indegree_pagerank_diff = [x[1] for x in differences]\n",
    "hits_pagerank_diff = [x[2] for x in differences]\n",
    "hits_ours_vs_networkx_diff = [x[3] for x in differences]\n",
    "pagerank_ours_vs_networkx_diff = [x[4] for x in differences]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='In-degree vs HITS', x=graphs, y=indegree_hits_diff),\n",
    "    go.Bar(name='In-degree vs PageRank', x=graphs, y=indegree_pagerank_diff),\n",
    "    go.Bar(name='HITS vs PageRank', x=graphs, y=hits_pagerank_diff),\n",
    "    go.Bar(name='Our HITS implementation vs networkx\\'', x=graphs, y=hits_ours_vs_networkx_diff),\n",
    "    go.Bar(name='Our PageRank implementation vs networkx\\'', x=graphs, y=pagerank_ours_vs_networkx_diff)  \n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO explanation\n",
    "# TODO graph title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
